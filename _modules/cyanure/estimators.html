<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>cyanure.estimators &mdash; Cyanure 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Cyanure
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../welcome.html">Welcome to Cyanure’s documentation!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../welcome.html#license">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../welcome.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pythonAPI/pythonAPI.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Cyanure</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>cyanure.estimators</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for cyanure.estimators</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Contain the different estimators of the library.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span><span class="p">,</span> <span class="n">ABC</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span>

<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">safe_sparse_dot</span><span class="p">,</span> <span class="n">softmax</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">ConvergenceWarning</span>

<span class="kn">import</span> <span class="nn">cyanure_lib</span>

<span class="kn">from</span> <span class="nn">cyanure.data_processing</span> <span class="kn">import</span> <span class="n">check_input_fit</span><span class="p">,</span> <span class="n">check_input_inference</span>

<span class="kn">from</span> <span class="nn">cyanure.logger</span> <span class="kn">import</span> <span class="n">setup_custom_logger</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">setup_custom_logger</span><span class="p">(</span><span class="s2">&quot;INFO&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ERM</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The generic class for empirical risk minimization problems.</span>

<span class="sd">    For univariates problems, minimizes</span>

<span class="sd">        min_{w,b} (1/n) sum_{i=1}^n L( y_i, &lt;w, x_i&gt; + b)   + psi(w)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;requires_y&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">_warm_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">initial_weight</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;coef_&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Restart&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
                <span class="n">initial_weight</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
                <span class="n">initial_weight</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">initial_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;miso&#39;</span><span class="p">,</span> <span class="s1">&#39;catalyst-miso&#39;</span><span class="p">,</span> <span class="s1">&#39;qning-miso&#39;</span><span class="p">):</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># TODO Ecrire test pour dual surtout défensif</span>
            <span class="n">reset_dual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">reset_dual</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">:</span>
                <span class="n">reset_dual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">reset_dual</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">:</span>
                <span class="n">reset_dual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">reset_dual</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">reset_dual</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">initial_weight</span>

    <span class="k">def</span> <span class="nf">_initialize_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">nclasses</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="k">else</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">:</span>
            <span class="n">initial_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">yf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">nclasses</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">yf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nclasses</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;Windows&quot;</span><span class="p">:</span>
                    <span class="n">yf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">yf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
            <span class="n">initial_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">[</span><span class="n">p</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>

        <span class="n">initial_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_warm_start</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">initial_weight</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">initial_weight</span><span class="p">,</span> <span class="n">yf</span><span class="p">,</span> <span class="n">nclasses</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;square&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                 <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">fista_restart</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                 <span class="n">lambda_1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate the ERM class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loss: string, default=&#39;square&#39;</span>
<span class="sd">            Loss function to be used. Possible choices are</span>

<span class="sd">                - &#39;square&#39;</span>
<span class="sd">                    :math:`L(y,z) = \\frac{1}{2} ( y-z)^2`</span>
<span class="sd">                - &#39;logistic&#39;</span>
<span class="sd">                    :math:`L(y,z) = \\log(1 + e^{-y z} )`</span>
<span class="sd">                - &#39;sqhinge&#39; or &#39;squared_hinge&#39;</span>
<span class="sd">                    :math:`L(y,z) = \\frac{1}{2} \\max( 0, 1- y z)^2`</span>
<span class="sd">                - &#39;safe-logistic&#39;</span>
<span class="sd">                    :math:`L(y,z) = e^{ yz - 1 } - y z ~\\text{if}~ yz</span>
<span class="sd">                    \\leq 1~~\\text{and}~~0` otherwise</span>
<span class="sd">                - &#39;multiclass-logistic&#39;</span>
<span class="sd">                    which is also called multinomial or softmax logistic:</span>
<span class="sd">                    .. math::`L(y, W^\\top x + b) = \\sum_{j=1}^k</span>
<span class="sd">                    \\log\\left(e^{w_j^\\top + b_j} - e^{w_y^\\top + b_y} \\right)`</span>

<span class="sd">        penalty (string): default=&#39;none&#39;</span>
<span class="sd">            Regularization function psi. Possible choices are</span>

<span class="sd">            For binary_problem problems:</span>

<span class="sd">            - &#39;none&#39;</span>
<span class="sd">                :math:`psi(w) = 0`</span>
<span class="sd">            - &#39;l2&#39;</span>
<span class="sd">                :math:`psi(w) = \\frac{\\lambda_1}{2} ||w||_2^2`</span>
<span class="sd">            - &#39;l1&#39;</span>
<span class="sd">                :math:`psi(w) = \\lambda_1 ||w||_1`</span>
<span class="sd">            - &#39;elasticnet&#39;</span>
<span class="sd">                :math:`psi(w) = \\lambda_1 ||w||_1 + \\frac{\\lambda_2}{2}||w||_2^2`</span>
<span class="sd">            - &#39;fused-lasso&#39;</span>
<span class="sd">                :math:`psi(w) = \\lambda_3 \\sum_{i=2}^p |w[i]-w[i-1]| +</span>
<span class="sd">                \\lambda_1||w||_1 + \\frac{\\lambda_2}{2}||w||_2^2`</span>
<span class="sd">            - &#39;l1-ball&#39;</span>
<span class="sd">                encodes the constraint :math:`||w||_1 &lt;= \\lambda`</span>
<span class="sd">            - &#39;l2-ball&#39;</span>
<span class="sd">                encodes the constraint :math:`||w||_2 &lt;= \\lambda`</span>

<span class="sd">            For multivariate problems, the previous penalties operate on each</span>
<span class="sd">            individual (e.g., class) predictor.</span>

<span class="sd">            .. math::</span>
<span class="sd">                \\psi(W) = \\sum_{j=1}^k \\psi(w_j).</span>

<span class="sd">            In addition, multitask-group Lasso penalties are provided for</span>
<span class="sd">            multivariate problems (w is then a matrix)</span>

<span class="sd">            - &#39;l1l2&#39;, which is the multi-task group Lasso regularization</span>
<span class="sd">                .. math::</span>
<span class="sd">                    \\psi(W) = \\lambda \\sum_{j=1}^p \\|W^j\\|_2~~~~</span>
<span class="sd">                    \\text{where}~W^j~\\text{is the j-th row of}~W.</span>

<span class="sd">            - &#39;l1linf&#39;</span>
<span class="sd">                .. math::</span>
<span class="sd">                    \\psi(W) = \\lambda \\sum_{j=1}^p \\|W^j\\|_\\infty.</span>

<span class="sd">            - &#39;l1l2+l1&#39;, which is the multi-task group Lasso regularization + l1</span>
<span class="sd">                .. math::</span>
<span class="sd">                    \\psi(W) = \\sum_{j=1}^p \\lambda</span>
<span class="sd">                    \\|W^j\\|_2 + \\lambda_2 \\|W^j\\|_1 ~~~~</span>
<span class="sd">                    \\text{where}~W^j~\\text{is the j-th row of}~W.</span>

<span class="sd">        fit_intercept (boolean): default=&#39;False&#39;</span>
<span class="sd">            Learns an unregularized intercept b  (or several intercepts for</span>
<span class="sd">            multivariate problems)</span>

<span class="sd">        lambda_1 (float): default=0</span>
<span class="sd">            First regularization parameter</span>

<span class="sd">        lambda_2 (float): default=0</span>
<span class="sd">            Second regularization parameter, if needed</span>

<span class="sd">        lambda_3 (float): default=0</span>
<span class="sd">            Third regularization parameter, if needed</span>

<span class="sd">        solver (string): default=&#39;auto&#39;</span>
<span class="sd">            Optimization solver. Possible choices are</span>

<span class="sd">            - &#39;ista&#39;</span>
<span class="sd">            - &#39;fista&#39;</span>
<span class="sd">            - &#39;catalyst-ista&#39;</span>
<span class="sd">            - &#39;qning-ista&#39;  (proximal quasi-Newton method)</span>
<span class="sd">            - &#39;svrg&#39;</span>
<span class="sd">            - &#39;catalyst-svrg&#39; (accelerated SVRG with Catalyst)</span>
<span class="sd">            - &#39;qning-svrg&#39;  (quasi-Newton SVRG)</span>
<span class="sd">            - &#39;acc-svrg&#39;    (SVRG with direct acceleration)</span>
<span class="sd">            - &#39;miso&#39;</span>
<span class="sd">            - &#39;catalyst-miso&#39; (accelerated MISO with Catalyst)</span>
<span class="sd">            - &#39;qning-miso&#39;  (quasi-Newton MISO)</span>
<span class="sd">            - &#39;auto&#39;</span>

<span class="sd">            see the Latex documentation for more details.</span>
<span class="sd">            If you are unsure, use &#39;auto&#39;</span>

<span class="sd">        tol (float): default=&#39;1e-3&#39;</span>
<span class="sd">            Tolerance parameter. For almost all combinations of loss and</span>
<span class="sd">            penalty functions, this parameter is based on a duality gap.</span>
<span class="sd">            Assuming the (non-negative) objective function is &quot;f&quot; and its</span>
<span class="sd">            optimal value is &quot;f^*&quot;, the algorithm stops with the guarantee</span>

<span class="sd">            :math:`f(x_t) - f^*  &lt;=  tol f(x_t)`</span>

<span class="sd">        max_iter (int): default=500</span>
<span class="sd">            Maximum number of iteration of the algorithm in terms of passes</span>
<span class="sd">            over the data</span>

<span class="sd">        duality_gap_interval (int): default=10</span>
<span class="sd">            Frequency of duality-gap computation</span>

<span class="sd">        verbose (boolean): default=True</span>
<span class="sd">            Display information or not</span>

<span class="sd">        n_threads (int): default=-1</span>
<span class="sd">            Maximum number of cores the method may use (-1 = all cores).</span>
<span class="sd">            Note that more cores is not always better.</span>

<span class="sd">        random_state (int): default=0</span>
<span class="sd">            Random seed</span>

<span class="sd">        warm_start (boolean): default=False</span>
<span class="sd">            Use a restart strategy</span>

<span class="sd">        binary_problem (boolean): default=True</span>
<span class="sd">            univariate or multivariate problems</span>

<span class="sd">        limited_memory_qning (int): default=20</span>
<span class="sd">            Memory parameter for the qning method</span>

<span class="sd">        fista_restart (int): default=50</span>
<span class="sd">            Restart strategy for fista (useful for computing regularization path)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;squared_hinge&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;sqhinge&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="n">dual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_1</span> <span class="o">=</span> <span class="n">lambda_1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_2</span> <span class="o">=</span> <span class="n">lambda_2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_3</span> <span class="o">=</span> <span class="n">lambda_3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limited_memory_qning</span> <span class="o">=</span> <span class="n">limited_memory_qning</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fista_restart</span> <span class="o">=</span> <span class="n">fista_restart</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_class</span> <span class="o">=</span> <span class="n">multi_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">duality_gap_interval</span> <span class="o">=</span> <span class="n">duality_gap_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_threads</span> <span class="o">=</span> <span class="n">n_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">safe</span> <span class="o">=</span> <span class="n">safe</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">le_parameter</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                input n X p numpy matrix; the samples are on the rows</span>

<span class="sd">            y (numpy array):</span>
<span class="sd">                - vector of size n with real values for regression</span>
<span class="sd">                - vector of size n with {-1,+1} for binary classification,</span>
<span class="sd">                  which will be automatically converted if {0,1} are</span>
<span class="sd">                  provided</span>
<span class="sd">                - matrix of size n X k for multivariate regression</span>
<span class="sd">                - vector of size n with entries in {0,1,k-1} for classification</span>
<span class="sd">                  with k classes</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            self (ERM):</span>
<span class="sd">                Returns the instance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="o">=</span> <span class="n">le_parameter</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;multinomial&quot;</span> <span class="ow">or</span>
           <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;logistic&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;multinomial&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="s2">&quot;multiclass-logistic&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Loss has been set to multiclass-logistic because &quot;</span>
                <span class="s2">&quot;the multiclass parameter is set to multinomial!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">initial_weight</span><span class="p">,</span> <span class="n">yf</span><span class="p">,</span> <span class="n">nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weight</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">training_data_fortran</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span>
            <span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">initial_weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_info_</span> <span class="o">=</span> <span class="n">cyanure_lib</span><span class="o">.</span><span class="n">erm_</span><span class="p">(</span>
            <span class="n">training_data_fortran</span><span class="p">,</span> <span class="n">yf</span><span class="p">,</span> <span class="n">initial_weight</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">dual_variable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_1</span><span class="p">),</span>
            <span class="n">lambda_2</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_2</span><span class="p">),</span> <span class="n">lambda_3</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_3</span><span class="p">),</span>
            <span class="n">intercept</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">),</span>
            <span class="n">tol</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">),</span> <span class="n">duality_gap_interval</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">duality_gap_interval</span><span class="p">),</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">),</span> <span class="n">limited_memory_qning</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">limited_memory_qning</span><span class="p">),</span>
            <span class="n">fista_restart</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fista_restart</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">),</span>
            <span class="n">univariate</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">),</span>
            <span class="n">n_threads</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_threads</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;multinomial&quot;</span> <span class="ow">or</span>
           <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span><span class="p">))</span> <span class="ow">and</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;logistic&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_info_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimization_info_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimization_info_</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_info_</span><span class="p">[</span><span class="n">class_index</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">class_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_info_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>

        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;The max_iter was reached which means the coef_ did not converge&quot;</span><span class="p">,</span>
                    <span class="n">ConvergenceWarning</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">w</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict the labels given an input matrix X (same format as fit).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the model parameters (either w or the tuple (w,b)).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            w or (w,b) (numpy.array or tuple of numpy.array):</span>
<span class="sd">                Model parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get parameters for the estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            deep (bool, optional):</span>
<span class="sd">                If True returns also subobjects that are estimators. Defaults to True.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            params (dict):</span>
<span class="sd">                Parameters names and values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
                <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_get_param_namesrestart</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="n">init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span> <span class="s1">&#39;deprecated_original&#39;</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__init__</span><span class="p">:</span>
            <span class="c1"># No explicit constructor to introspect</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># introspect the constructor arguments to find the model parameters</span>
        <span class="c1"># to represent</span>
        <span class="n">init_signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="c1"># Consider the constructor parameters excluding &#39;self&#39;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">init_signature</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s1">&#39;self&#39;</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">VAR_KEYWORD</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">VAR_POSITIONAL</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">()</span>
        <span class="c1"># Extract and sort argument names excluding &#39;self&#39;</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allow to change the value of parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            params (dict):</span>
<span class="sd">                Estimator parameters to set</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">            ValueError:</span>
<span class="sd">                The parameter does not exist</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            self (ERM):</span>
<span class="sd">                Estimator instance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
            <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Grouped by prefix</span>
        <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid parameter </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> for estimator </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
                <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
                <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">densify</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert coefficient matrix to dense array format.</span>

<span class="sd">        Converts the ``coef_`` member (back) to a numpy.ndarray. This is the</span>
<span class="sd">        default format of ``coef_`` and is required for fitting, so calling</span>
<span class="sd">        this method is only required on models that have previously been</span>
<span class="sd">        sparsified; otherwise, it is a no-op.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self (ERM):</span>
<span class="sd">            Fitted estimator converted to dense estimator</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Estimator, </span><span class="si">%(name)s</span><span class="s2">, must be fitted before densifying.&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">sparsify</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert coefficient matrix to sparse format.</span>

<span class="sd">        Converts the ``coef_`` member to a scipy.sparse matrix, which for</span>
<span class="sd">        L1-regularized models can be much more memory- and storage-efficient</span>
<span class="sd">        than the usual numpy.ndarray representation.</span>
<span class="sd">        The ``intercept_`` member is not converted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self (ERM):</span>
<span class="sd">            Fitted estimator converted to parse estimator.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For non-sparse models, i.e. when there are not many zeros in ``coef_``,</span>
<span class="sd">        this may actually *increase* memory usage, so use this method with</span>
<span class="sd">        care. A rule of thumb is that the number of zero elements, which can</span>
<span class="sd">        be computed with ``(coef_ == 0).sum()``, must be more than 50% for this</span>
<span class="sd">        to provide significant benefits.</span>
<span class="sd">        After calling this method, further fitting with the partial_fit</span>
<span class="sd">        method (if any) will not work until you call densify.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Estimator, </span><span class="si">%(name)s</span><span class="s2">, must be fitted before sparsifying.&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="bp">self</span>


<span class="k">class</span> <span class="nc">ClassifierAbstraction</span><span class="p">(</span><span class="n">ERM</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A class to define abstract methods for classifiers.&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the probability for each class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                Data matrix for which we want probabilities</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            proba (numpy.array):</span>
<span class="sd">                Return the probability of the samples for each class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>


<div class="viewcode-block" id="Regression"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Regression">[docs]</a><span class="k">class</span> <span class="nc">Regression</span><span class="p">(</span><span class="n">ERM</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The regression class which derives from ERM.</span>

<span class="sd">    The goal is to minimize the following objective:</span>

<span class="sd">        .. math::</span>
<span class="sd">            \min_{w,b} \frac{1}{n} \sum_{i=1}^n</span>
<span class="sd">            L\left( y_i, w^\top x_i + b\right) + \psi(w),</span>

<span class="sd">        where :math:`L` is a regression loss, :math:`\\psi` is a</span>
<span class="sd">        regularization function (or constraint), :math:`w` is a p-dimensional</span>
<span class="sd">        vector representing model parameters, and b is an optional</span>
<span class="sd">        unregularized intercept., and the targets will be real values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        loss (string): default=&#39;square&#39;</span>
<span class="sd">            Loss function to be used. Possible choices are:</span>
<span class="sd">            Only the square loss is implemented at this point. Given two</span>
<span class="sd">            k-dimensional vectors y,z:</span>

<span class="sd">            * &#39;square&#39; =&gt;  :math:`L(y,z) = \frac{1}{2}( y-z)^2`</span>

<span class="sd">        penalty (string): default=&#39;none&#39;</span>
<span class="sd">            Regularization function psi. Possible choices are</span>

<span class="sd">            For binary_problem problems:</span>

<span class="sd">            - &#39;none&#39;</span>
<span class="sd">                :math:`psi(w) = 0`</span>
<span class="sd">            - &#39;l2&#39;</span>
<span class="sd">                :math:`psi(w) = \frac{\lambda_1}{2} ||w||_2^2`</span>
<span class="sd">            - &#39;l1</span>
<span class="sd">                :math:`psi(w) = \lambda_1 ||w||_1`</span>
<span class="sd">            - &#39;elasticnet&#39;</span>
<span class="sd">                :math:`psi(w) = \lambda_1 ||w||_1 + \frac{\lambda_2}{2}||w||_2^2`</span>
<span class="sd">            - &#39;fused-lasso&#39;</span>
<span class="sd">                :math:`psi(w) = \lambda_3 \sum_{i=2}^p |w[i]-w[i-1]|</span>
<span class="sd">                + \lambda_1||w||_1 + \frac{\lambda_2}{2}||w||_2^2`</span>
<span class="sd">            - &#39;l1-ball&#39;</span>
<span class="sd">                encodes the constraint :math:`||w||_1 &lt;= \lambda`</span>
<span class="sd">            - &#39;l2-ball&#39;</span>
<span class="sd">                encodes the constraint :math:`||w||_2 &lt;= \lambda`</span>

<span class="sd">            For multivariate problems, the previous penalties operate on each</span>
<span class="sd">            individual (e.g., class) predictor.</span>

<span class="sd">            .. math::</span>
<span class="sd">                \psi(W) = \sum_{j=1}^k \psi(w_j).</span>

<span class="sd">            In addition, multitask-group Lasso penalties are provided for</span>
<span class="sd">            multivariate problems (w is then a matrix)</span>

<span class="sd">            - &#39;l1l2&#39;, which is the multi-task group Lasso regularization</span>
<span class="sd">                .. math::</span>
<span class="sd">                    \psi(W) = \lambda \sum_{j=1}^p \|W^j\|_2~~~~</span>
<span class="sd">                    \text{where}~W^j~\text{is the j-th row of}~W.</span>

<span class="sd">            - &#39;l1linf&#39;</span>
<span class="sd">                .. math::</span>
<span class="sd">                    \psi(W) = \lambda \sum_{j=1}^p \|W^j\|_\infty.</span>

<span class="sd">            - &#39;l1l2+l1&#39;, which is the multi-task group Lasso regularization + l1</span>
<span class="sd">                .. math::</span>
<span class="sd">                    \psi(W) = \sum_{j=1}^p \lambda \|W^j\|_2 + \lambda_2 \|W^j\|_1 ~~~~</span>
<span class="sd">                    \text{where}~W^j~\text{is the j-th row of}~W.</span>

<span class="sd">        fit_intercept (boolean): default=&#39;False&#39;</span>
<span class="sd">            Learns an unregularized intercept b  (or several intercepts for</span>
<span class="sd">            multivariate problems)</span>

<span class="sd">        lambda_1 (float): default=0</span>
<span class="sd">            First regularization parameter</span>

<span class="sd">        lambda_2 (float): default=0</span>
<span class="sd">            Second regularization parameter, if needed</span>

<span class="sd">        lambda_3 (float): default=0</span>
<span class="sd">            Third regularization parameter, if needed</span>

<span class="sd">        solver (string): default=&#39;auto&#39;</span>
<span class="sd">            Optimization solver. Possible choices are</span>

<span class="sd">            - &#39;ista&#39;</span>
<span class="sd">            - &#39;fista&#39;</span>
<span class="sd">            - &#39;catalyst-ista&#39;</span>
<span class="sd">            - &#39;qning-ista&#39;  (proximal quasi-Newton method)</span>
<span class="sd">            - &#39;svrg&#39;</span>
<span class="sd">            - &#39;catalyst-svrg&#39; (accelerated SVRG with Catalyst)</span>
<span class="sd">            - &#39;qning-svrg&#39;  (quasi-Newton SVRG)</span>
<span class="sd">            - &#39;acc-svrg&#39;    (SVRG with direct acceleration)</span>
<span class="sd">            - &#39;miso&#39;</span>
<span class="sd">            - &#39;catalyst-miso&#39; (accelerated MISO with Catalyst)</span>
<span class="sd">            - &#39;qning-miso&#39;  (quasi-Newton MISO)</span>
<span class="sd">            - &#39;auto&#39;</span>

<span class="sd">            see the Latex documentation for more details.</span>
<span class="sd">            If you are unsure, use &#39;auto&#39;</span>

<span class="sd">        tol (float): default=&#39;1e-3&#39;</span>
<span class="sd">            Tolerance parameter. For almost all combinations of loss and</span>
<span class="sd">            penalty functions, this parameter is based on a duality gap.</span>
<span class="sd">            Assuming the (non-negative) objective function is &quot;f&quot; and its</span>
<span class="sd">            optimal value is &quot;f^*&quot;, the algorithm stops with the guarantee</span>

<span class="sd">            :math:`f(x_t) - f^*  &lt;=  tol f(x_t)`</span>

<span class="sd">        max_iter (int): default=500</span>
<span class="sd">            Maximum number of iteration of the algorithm in terms of passes</span>
<span class="sd">            over the data</span>

<span class="sd">        duality_gap_interval (int): default=10</span>
<span class="sd">            Frequency of duality-gap computation</span>

<span class="sd">        verbose (boolean): default=True</span>
<span class="sd">            Display information or not</span>

<span class="sd">        n_threads (int): default=-1</span>
<span class="sd">            Maximum number of cores the method may use (-1 = all cores).</span>
<span class="sd">            Note that more cores is not always better.</span>

<span class="sd">        random_state (int): default=0</span>
<span class="sd">            Random seed</span>

<span class="sd">        warm_start (boolean): default=False</span>
<span class="sd">            Use a restart strategy</span>

<span class="sd">        binary_problem (boolean): default=True</span>
<span class="sd">            univariate or multivariate problems</span>

<span class="sd">        limited_memory_qning (int): default=20</span>
<span class="sd">            Memory parameter for the qning method</span>

<span class="sd">        fista_restart (int): default=50</span>
<span class="sd">            Restart strategy for fista (useful for computing regularization path)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;regressor&quot;</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;multioutput&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;requires_y&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;square&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">lambda_1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                 <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                 <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">fista_restart</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="o">!=</span> <span class="s1">&#39;square&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;square loss should be used&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span>
                         <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="n">lambda_1</span><span class="p">,</span>
                         <span class="n">lambda_2</span><span class="o">=</span><span class="n">lambda_2</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="n">lambda_3</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                         <span class="n">duality_gap_interval</span><span class="o">=</span><span class="n">duality_gap_interval</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                         <span class="n">limited_memory_qning</span><span class="o">=</span><span class="n">limited_memory_qning</span><span class="p">,</span>
                         <span class="n">fista_restart</span><span class="o">=</span><span class="n">fista_restart</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                         <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>

<div class="viewcode-block" id="Regression.fit"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Regression.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">le_parameter</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                input n X p numpy matrix; the samples are on the rows</span>

<span class="sd">            y (numpy array):</span>
<span class="sd">                - vector of size n with real values for regression</span>
<span class="sd">                - matrix of size n X k for multivariate regression</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            self (ERM):</span>
<span class="sd">                Returns the instance of the class</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">check_input_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span>

        <span class="k">if</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">le_parameter</span><span class="p">)</span></div>

<div class="viewcode-block" id="Regression.predict"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Regression.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the labels given an input matrix X (same format as fit).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                Input matrix for the prediction</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            pred (numpy.array):</span>
<span class="sd">                Prediction for the X matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_input_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>

<div class="viewcode-block" id="Regression.score"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Regression.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the coefficient of determination of the prediction.</span>

<span class="sd">        The coefficient of determination :math:`R^2` is defined as</span>
<span class="sd">        :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual</span>
<span class="sd">        sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`</span>
<span class="sd">        is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.</span>
<span class="sd">        The best possible score is 1.0 and it can be negative (because the</span>
<span class="sd">        model can be arbitrarily worse). A constant model that always predicts</span>
<span class="sd">        the expected value of `y`, disregarding the input features, would get</span>
<span class="sd">        a :math:`R^2` score of 0.0.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                Test samples.</span>
<span class="sd">            y (numpy.array):</span>
<span class="sd">                True labels for X.</span>
<span class="sd">            sample_weight (numpy.array, optional):</span>
<span class="sd">                Sample weights. Defaults to None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            score (float):</span>
<span class="sd">                :math:`R^2` of ``self.predict(X)`` wrt. `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Classifier"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Classifier">[docs]</a><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">ClassifierAbstraction</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The classification class.</span>

<span class="sd">    The goal is to minimize the following objective:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \min_{W,b} \frac{1}{n} \sum_{i=1}^n</span>
<span class="sd">        L\left( y_i, W^\top x_i + b\right) + \psi(W)</span>

<span class="sd">    where :math:`L` is a classification loss, :math:`\psi` is a regularization</span>
<span class="sd">    function (or constraint), :math:`W=[w_1,\ldots,w_k]` is a (p x k) matrix</span>
<span class="sd">    that carries the k predictors, where k is the number of classes, and</span>
<span class="sd">    :math:`y_i` is a label in :math:`\{1,\ldots,k\}`.</span>
<span class="sd">    b is a k-dimensional vector representing an unregularized intercept</span>
<span class="sd">    (which is optional).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    loss: string, default=&#39;square&#39;</span>
<span class="sd">        Loss function to be used. Possible choices are</span>

<span class="sd">            - &#39;square&#39;</span>
<span class="sd">                :math:`L(y,z) = \frac{1}{2} ( y-z)^2`</span>
<span class="sd">            - &#39;logistic&#39;</span>
<span class="sd">                :math:`L(y,z) = \log(1 + e^{-y z} )`</span>
<span class="sd">            - &#39;sqhinge&#39; or &#39;squared_hinge&#39;</span>
<span class="sd">                :math:`L(y,z) = \frac{1}{2} \max( 0, 1- y z)^2`</span>
<span class="sd">            - &#39;safe-logistic&#39;</span>
<span class="sd">                :math:`L(y,z) = e^{ yz - 1 } - y z</span>
<span class="sd">                ~\text{if}~ yz \leq 1~~\text{and}~~0` otherwise</span>
<span class="sd">            - &#39;multiclass-logistic&#39;</span>
<span class="sd">                which is also called multinomial or softmax logistic:</span>
<span class="sd">                :math:`L(y, W^\top x + b) = \sum_{j=1}^k</span>
<span class="sd">                \log\left(e^{w_j^\top + b_j} - e^{w_y^\top + b_y} \right)`</span>

<span class="sd">    penalty (string): default=&#39;none&#39;</span>
<span class="sd">        Regularization function psi. Possible choices are</span>

<span class="sd">        For binary_problem problems:</span>

<span class="sd">        - &#39;none&#39;</span>
<span class="sd">            :math:`psi(w) = 0`</span>
<span class="sd">        - &#39;l2&#39;</span>
<span class="sd">            :math:`psi(w) = \frac{\lambda_1}{2} ||w||_2^2`</span>
<span class="sd">        - &#39;l1&#39;</span>
<span class="sd">            :math:`psi(w) = \lambda_1 ||w||_1`</span>
<span class="sd">        - &#39;elasticnet&#39;</span>
<span class="sd">            :math:`psi(w) = \lambda_1 ||w||_1 + \frac{\lambda_2}{2}||w||_2^2`</span>
<span class="sd">        - &#39;fused-lasso&#39;</span>
<span class="sd">            :math:`psi(w) = \lambda_3 \sum_{i=2}^p |w[i]-w[i-1]| +</span>
<span class="sd">            \lambda_1||w||_1 + \frac{\lambda_2}{2}||w||_2^2`</span>
<span class="sd">        - &#39;l1-ball&#39;</span>
<span class="sd">            encodes the constraint :math:`||w||_1 &lt;= \lambda`</span>
<span class="sd">        - &#39;l2-ball&#39;</span>
<span class="sd">            encodes the constraint :math:`||w||_2 &lt;= \lambda`</span>

<span class="sd">        For multivariate problems, the previous penalties operate on each</span>
<span class="sd">        individual (e.g., class) predictor.</span>

<span class="sd">        .. math::</span>
<span class="sd">            \psi(W) = \sum_{j=1}^k \psi(w_j).</span>

<span class="sd">        In addition, multitask-group Lasso penalties are provided for</span>
<span class="sd">        multivariate problems (w is then a matrix)</span>

<span class="sd">        - &#39;l1l2&#39;, which is the multi-task group Lasso regularization</span>
<span class="sd">            .. math::</span>
<span class="sd">                \psi(W) = \lambda \sum_{j=1}^p \|W^j\|_2~~~~</span>
<span class="sd">                \text{where}~W^j~\text{is the j-th row of}~W.</span>

<span class="sd">        - &#39;l1linf&#39;</span>
<span class="sd">            .. math::</span>
<span class="sd">                \psi(W) = \lambda \sum_{j=1}^p \|W^j\|_\infty.</span>

<span class="sd">        - &#39;l1l2+l1&#39;, which is the multi-task group Lasso regularization + l1</span>
<span class="sd">            .. math::</span>
<span class="sd">                \psi(W) = \sum_{j=1}^p \lambda \|W^j\|_2 + \lambda_2 \|W^j\|_1 ~~~~</span>
<span class="sd">                \text{where}~W^j~\text{is the j-th row of}~W.</span>

<span class="sd">    fit_intercept (boolean): default=&#39;False&#39;</span>
<span class="sd">        Learns an unregularized intercept b  (or several intercepts for</span>
<span class="sd">        multivariate problems)</span>

<span class="sd">    lambda_1 (float): default=0</span>
<span class="sd">        First regularization parameter</span>

<span class="sd">    lambda_2 (float): default=0</span>
<span class="sd">        Second regularization parameter, if needed</span>

<span class="sd">    lambda_3 (float): default=0</span>
<span class="sd">        Third regularization parameter, if needed</span>

<span class="sd">    solver (string): default=&#39;auto&#39;</span>
<span class="sd">        Optimization solver. Possible choices are</span>

<span class="sd">        - &#39;ista&#39;</span>
<span class="sd">        - &#39;fista&#39;</span>
<span class="sd">        - &#39;catalyst-ista&#39;</span>
<span class="sd">        - &#39;qning-ista&#39;  (proximal quasi-Newton method)</span>
<span class="sd">        - &#39;svrg&#39;</span>
<span class="sd">        - &#39;catalyst-svrg&#39; (accelerated SVRG with Catalyst)</span>
<span class="sd">        - &#39;qning-svrg&#39;  (quasi-Newton SVRG)</span>
<span class="sd">        - &#39;acc-svrg&#39;    (SVRG with direct acceleration)</span>
<span class="sd">        - &#39;miso&#39;</span>
<span class="sd">        - &#39;catalyst-miso&#39; (accelerated MISO with Catalyst)</span>
<span class="sd">        - &#39;qning-miso&#39;  (quasi-Newton MISO)</span>
<span class="sd">        - &#39;auto&#39;</span>

<span class="sd">        see the Latex documentation for more details.</span>
<span class="sd">        If you are unsure, use &#39;auto&#39;</span>

<span class="sd">    tol (float): default=&#39;1e-3&#39;</span>
<span class="sd">        Tolerance parameter. For almost all combinations of loss and</span>
<span class="sd">        penalty functions, this parameter is based on a duality gap.</span>
<span class="sd">        Assuming the (non-negative) objective function is &quot;f&quot; and its</span>
<span class="sd">        optimal value is &quot;f^*&quot;, the algorithm stops with the guarantee</span>

<span class="sd">        :math:`f(x_t) - f^*  &lt;=  tol f(x_t)`</span>

<span class="sd">    max_iter (int): default=500</span>
<span class="sd">        Maximum number of iteration of the algorithm in terms of passes</span>
<span class="sd">        over the data</span>

<span class="sd">    duality_gap_interval (int): default=10</span>
<span class="sd">        Frequency of duality-gap computation</span>

<span class="sd">    verbose (boolean): default=True</span>
<span class="sd">        Display information or not</span>

<span class="sd">    n_threads (int): default=-1</span>
<span class="sd">        Maximum number of cores the method may use (-1 = all cores).</span>
<span class="sd">        Note that more cores is not always better.</span>

<span class="sd">    random_state (int): default=0</span>
<span class="sd">        Random seed</span>

<span class="sd">    warm_start (boolean): default=False</span>
<span class="sd">        Use a restart strategy</span>

<span class="sd">    binary_problem (boolean): default=True</span>
<span class="sd">        univariate or multivariate problems</span>

<span class="sd">    limited_memory_qning (int): default=20</span>
<span class="sd">        Memory parameter for the qning method</span>

<span class="sd">    fista_restart (int): default=50</span>
<span class="sd">        Restart strategy for fista (useful for computing regularization path)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;classifier&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;square&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">fista_restart</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                 <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span>
                         <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">fista_restart</span><span class="o">=</span><span class="n">fista_restart</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span>
                         <span class="n">limited_memory_qning</span><span class="o">=</span><span class="n">limited_memory_qning</span><span class="p">,</span>
                         <span class="n">lambda_1</span><span class="o">=</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="n">lambda_2</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="n">lambda_3</span><span class="p">,</span>
                         <span class="n">duality_gap_interval</span><span class="o">=</span><span class="n">duality_gap_interval</span><span class="p">,</span>
                         <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="n">multi_class</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>

<div class="viewcode-block" id="Classifier.fit"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Classifier.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">le_parameter</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X (numpy array, or scipy sparse CSR matrix):</span>
<span class="sd">            input n x p numpy matrix; the samples are on the rows</span>

<span class="sd">        y (numpy.array):</span>
<span class="sd">            Input labels.</span>

<span class="sd">            - vector of size n with {-1, +1} labels for binary classification,</span>
<span class="sd">              which will be automatically converted if labels in {0,1} are</span>
<span class="sd">              provided and {0,1,..., n} for multiclass classification.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">le</span> <span class="o">=</span> <span class="n">check_input_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span>
            <span class="n">le</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">le_parameter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="o">=</span> <span class="n">le_parameter</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="o">=</span> <span class="n">le</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">nb_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span><span class="o">.</span><span class="n">classes_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">unique</span>

        <span class="k">if</span> <span class="n">nb_classes</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="p">(</span><span class="n">nb_classes</span> <span class="o">!=</span> <span class="n">unique</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">or</span>
                                <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nb_classes</span><span class="p">))):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Class labels should be of the form&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nb_classes</span><span class="p">))</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;but they are&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">unique</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;The labels have been converted to respect the expected format.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">nb_classes</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">neg</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">neg</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">neg</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">min_value</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">min_value</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">-</span> <span class="n">min_value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_binary_problem</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">le_parameter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">le_</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Classifier.predict"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Classifier.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the labels given an input matrix X (same format as fit).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                Input matrix for the prediction</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            pred (numpy.array):</span>
<span class="sd">                Prediction for the X matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_input_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
                <span class="n">output</span><span class="p">[</span><span class="n">output</span> <span class="o">==</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
                <span class="n">output</span><span class="p">[</span><span class="n">output</span> <span class="o">==</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">le_</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Classifier.score"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Classifier.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Give an accuracy score on test data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                Test samples.</span>
<span class="sd">            y (numpy.array):</span>
<span class="sd">                True labels for X.</span>
<span class="sd">            sample_weight (numpy.array, optional):</span>
<span class="sd">                Sample weights. Defaults to None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            score : float</span>
<span class="sd">                Mean accuracy of ``self.predict(X)`` wrt. `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_input_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">==</span> <span class="n">pred</span><span class="p">)</span> <span class="o">/</span> <span class="n">pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="Classifier.decision_function"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Classifier.decision_function">[docs]</a>    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict confidence scores for samples.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                The data for which we want scores</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            scores (numpy.array):</span>
<span class="sd">                Confidence scores per (n_samples, n_classes) combination.</span>
<span class="sd">                In the binary case, confidence score for self.classes_[1] where &gt;0 means t</span>
<span class="sd">                his class would be predicted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_input_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="k">if</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">scores</span>

        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Classifier.predict_proba"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Classifier.predict_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the probability for each class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                Data matrix for which we want probabilities</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            proba (numpy.array):</span>
<span class="sd">                Return the probability of the samples for each class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_input_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">decision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">decision</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Workaround for binary outcomes</span>
            <span class="c1"># which requires softmax prediction with only a 1D decision.</span>
            <span class="n">decision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="o">-</span><span class="n">decision</span><span class="p">,</span> <span class="n">decision</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">decision</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LinearSVC"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.LinearSVC">[docs]</a><span class="k">class</span> <span class="nc">LinearSVC</span><span class="p">(</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A pre-configured class for square hinge loss.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sqhinge&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                 <span class="n">fista_restart</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;squared_hinge&#39;</span><span class="p">,</span> <span class="s1">&#39;sqhinge&#39;</span><span class="p">]:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;LinearSVC is only compatible with squared hinge loss at &quot;</span>
                         <span class="s2">&quot;the moment&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">lambda_1</span><span class="o">=</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="n">lambda_2</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="n">lambda_3</span><span class="p">,</span>
            <span class="n">duality_gap_interval</span><span class="o">=</span><span class="n">duality_gap_interval</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">limited_memory_qning</span><span class="o">=</span><span class="n">limited_memory_qning</span><span class="p">,</span>
            <span class="n">fista_restart</span><span class="o">=</span><span class="n">fista_restart</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span></div>


<div class="viewcode-block" id="LogisticRegression"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.LogisticRegression">[docs]</a><span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A pre-configured class for logistic regression loss.&quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;classifier&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                 <span class="n">fista_restart</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span>
                         <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                         <span class="n">lambda_1</span><span class="o">=</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">lambda_2</span><span class="o">=</span><span class="n">lambda_2</span><span class="p">,</span> <span class="n">lambda_3</span><span class="o">=</span><span class="n">lambda_3</span><span class="p">,</span>
                         <span class="n">duality_gap_interval</span><span class="o">=</span><span class="n">duality_gap_interval</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                         <span class="n">limited_memory_qning</span><span class="o">=</span><span class="n">limited_memory_qning</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="n">multi_class</span><span class="p">,</span>
                         <span class="n">fista_restart</span><span class="o">=</span><span class="n">fista_restart</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span>
                         <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">compute_r</span><span class="p">(</span><span class="n">estimator_name</span><span class="p">,</span> <span class="n">aux</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">active_set</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute R coefficient corresponding to the estimator.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        estimator_name (string):</span>
<span class="sd">            Name of the estimator class</span>

<span class="sd">        aux (ERM):</span>
<span class="sd">            Auxiliary estimator</span>

<span class="sd">        X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">            Features matrix</span>

<span class="sd">        labels (numpy.array):</span>
<span class="sd">            Labels matrix</span>

<span class="sd">        active_set (numpy.array):</span>
<span class="sd">            Active set</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        R (float):</span>
<span class="sd">            _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">R</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">aux</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">active_set</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">estimator_name</span> <span class="o">==</span> <span class="s2">&quot;Lasso&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">R</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">R</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">-</span> <span class="n">pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">estimator_name</span> <span class="o">==</span> <span class="s2">&quot;L1Logistic&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">R</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">labels</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">R</span> <span class="o">=</span> <span class="o">-</span><span class="n">labels</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">*</span> <span class="n">pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">+=</span> <span class="n">aux</span><span class="o">.</span><span class="n">intercept_</span>

    <span class="k">return</span> <span class="n">R</span>


<span class="k">def</span> <span class="nf">fit_large_feature_number</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">aux</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fitting function when the number of feature is superior to 1000.</span>

<span class="sd">    Args</span>
<span class="sd">    ----</span>
<span class="sd">        estimator (ERM):</span>
<span class="sd">            Fitted estimator</span>

<span class="sd">        aux (ERM):</span>
<span class="sd">            Auxiliary estimator</span>

<span class="sd">        X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">            Features matrix</span>

<span class="sd">        labels (numpy.array):</span>
<span class="sd">            Labels matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">scaling</span> <span class="o">=</span> <span class="mf">4.0</span>
    <span class="n">init</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">restart</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">num_as</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">init</span><span class="p">)</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">scaling</span><span class="p">))</span>
    <span class="n">active_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_active</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">estimator</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">estimator_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_as</span><span class="p">):</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">compute_r</span><span class="p">(</span><span class="n">estimator_name</span><span class="p">,</span> <span class="n">aux</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">active_set</span><span class="p">,</span> <span class="n">estimator</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">)</span>

        <span class="n">corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span> <span class="o">/</span> <span class="n">n</span>

        <span class="k">if</span> <span class="n">n_active</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">corr</span><span class="p">[</span><span class="n">active_set</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10e10</span>

        <span class="n">n_new_as</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
            <span class="nb">min</span><span class="p">(</span><span class="n">init</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">scaling</span> <span class="o">**</span> <span class="n">ii</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_active</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">new_as</span> <span class="o">=</span> <span class="n">corr</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="o">-</span><span class="n">n_new_as</span><span class="p">:]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_as</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">max</span><span class="p">(</span><span class="n">corr</span><span class="p">[</span><span class="n">new_as</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">lambda_1</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">estimator</span><span class="o">.</span><span class="n">tol</span><span class="p">):</span>
            <span class="k">break</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">neww</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_active</span> <span class="o">+</span> <span class="n">n_new_as</span><span class="p">,</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">neww</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n_active</span><span class="p">]</span> <span class="o">=</span> <span class="n">aux</span><span class="o">.</span><span class="n">coef_</span>
            <span class="n">aux</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">neww</span>
            <span class="n">active_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">active_set</span><span class="p">,</span> <span class="n">new_as</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">active_set</span> <span class="o">=</span> <span class="n">new_as</span>
            <span class="n">aux</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">n_active</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">estimator</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Size of the active set: {</span><span class="si">%d</span><span class="s2">}&quot;</span><span class="p">,</span> <span class="n">n_active</span><span class="p">)</span>

        <span class="n">aux</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">active_set</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">active_set</span><span class="p">]</span> <span class="o">=</span> <span class="n">aux</span><span class="o">.</span><span class="n">coef_</span>
        <span class="k">if</span> <span class="n">estimator</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">aux</span><span class="o">.</span><span class="n">intercept_</span>


<div class="viewcode-block" id="Lasso"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Lasso">[docs]</a><span class="k">class</span> <span class="nc">Lasso</span><span class="p">(</span><span class="n">Regression</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A pre-configured class for Lasso regression.</span>

<span class="sd">    Using active set when the number of features is superior to 1000.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                 <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                 <span class="n">fista_restart</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;square&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                         <span class="n">duality_gap_interval</span><span class="o">=</span><span class="n">duality_gap_interval</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                         <span class="n">limited_memory_qning</span><span class="o">=</span><span class="n">limited_memory_qning</span><span class="p">,</span> <span class="n">fista_restart</span><span class="o">=</span><span class="n">fista_restart</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>

<div class="viewcode-block" id="Lasso.fit"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.Lasso.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            X (numpy array or scipy sparse CSR matrix):</span>
<span class="sd">                input n X p numpy matrix; the samples are on the rows</span>

<span class="sd">            y (numpy array):</span>
<span class="sd">                - vector of size n with real values for regression</span>
<span class="sd">                - matrix of size n X k for multivariate regression</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            self (ERM):</span>
<span class="sd">                Returns the instance of the class</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">check_input_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="c1"># no active set</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="n">Regression</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;square&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span>
                             <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                             <span class="n">lambda_1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">,</span>
                             <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span> <span class="n">duality_gap_interval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">duality_gap_interval</span><span class="p">,</span>
                             <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

            <span class="n">fit_large_feature_number</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aux</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="L1Logistic"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.L1Logistic">[docs]</a><span class="k">class</span> <span class="nc">L1Logistic</span><span class="p">(</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A pre-configured class for L1 logistic classification.</span>

<span class="sd">    Using active set when the number of features is superior to 1000</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;classifier&quot;</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;requires_y&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="s2">&quot;_xfail_checks&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;check_non_transformer_estimators_n_iter&quot;</span><span class="p">:</span> <span class="p">(</span>
                    <span class="s2">&quot;We have a different implementation of _n_iter in the multinomial case.&quot;</span>
                <span class="p">),</span>
                <span class="p">}}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                 <span class="n">duality_gap_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">limited_memory_qning</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                 <span class="n">fista_restart</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">lambda_1</span><span class="o">=</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                         <span class="n">duality_gap_interval</span><span class="o">=</span><span class="n">duality_gap_interval</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                         <span class="n">limited_memory_qning</span><span class="o">=</span><span class="n">limited_memory_qning</span><span class="p">,</span>
                         <span class="n">fista_restart</span><span class="o">=</span><span class="n">fista_restart</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                         <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                         <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="n">multi_class</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="n">dual</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;multinomial&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="s2">&quot;multiclass-logistic&quot;</span>

<div class="viewcode-block" id="L1Logistic.fit"><a class="viewcode-back" href="../../pythonAPI/estimators.html#cyanure.estimators.L1Logistic.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X (numpy array, or scipy sparse CSR matrix):</span>
<span class="sd">            input n x p numpy matrix; the samples are on the rows</span>

<span class="sd">        y (numpy.array):</span>
<span class="sd">            Input labels.</span>

<span class="sd">            - vector of size n with {-1, +1} labels for binary classification,</span>
<span class="sd">              which will be automatically converted if labels in {0,1} are</span>
<span class="sd">              provided and {0,1,..., n} for multiclass classification.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">le</span> <span class="o">=</span> <span class="n">check_input_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">le</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">le_</span> <span class="o">=</span> <span class="n">le</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="c1"># no active set</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">le_parameter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">le_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span>
                <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                <span class="n">lambda_1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">safe</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">duality_gap_interval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">duality_gap_interval</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

            <span class="n">fit_large_feature_number</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aux</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, Julien Mairal.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>